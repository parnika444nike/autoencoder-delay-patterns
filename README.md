
# Autoencoders to Detect Delay Patterns

A neural network model built to analyse and discover delay patterns in product/shipment lifecycles. The model is developed with an autoencoder to be scalable and work on high dimensionality data with ease.


## 1. Tech Stack

With the following languages and concepts, the neural network was built.

- **Python**

- **Machine Learning fundamentals**

- **Neural Networks**

- **Linear Algebra**

- **Autoencoders**


## 2. Problem Statement 

With thousands of customers orders generated on a daily basis, tracking delays and recognising patterns become difficult. Being unable to detect common areas and patterns in delay causes three major issues -
 - No right direction in optimizing shipment processes.
 - Potential customers cannot be guaranteed delivery dates in advance. 
 - Unsatisfactory customer experience.

 ## 3. Approach of Solution 

 Let us consider the following product lifecycle- 

 **Factory** -> **Port A** -> **Port B** -> **DC** -> **Hubs** -> **Consumers**

 As we can see, there are 9 time periods - 
 - Leave Factory - Reach Port A
 - Reach Port A - Leave Port A
 - Leave Port A - Reach Port B
 - Reach Port B - Leave Port B
 - Leave Port B - Reach DC
 - Reach DC - Leave DC
 - Leave DC - Reach Hub
 - Reach Hub - Leave Hub
 - Leave Hub - Reach Consumers

 If we set a threshold value to all these 9 time periods, any value exceeding such thresholds will be considered as a delay. A delay can be marked as 1 and a no-delay can be marked as 0.

 This gives us 9 inputs having values as either 0 or 1. We can feed this into the neural network for further training. 



## 4. How It Works
We follow a 9-6-3-6-9 archietecture here. 

![Image](https://github.com/user-attachments/assets/7675c478-edec-4d16-806b-7525d29f4d31)

- The neural network recieves 9 inputs (0 or 1). This establishes our first input layer of nine neurons. 

- We have used an Autoencoder model, which is a type of artificial neural network. It works in 2 phases - Encoding and Decoding. 

- As neural networks work on data with high dimensionality, we use encoders that basically compress the input into a layer with 6 neurons. This gives us the second layer.

- The encoder works one more time and compresses the input via three neurons, this is the second hidden layer. 
 
- The decoder starts working now, to reconstruct or decompress the data. Giving us another hidden layer of 6 neurons.

- Finally, the output layer of 9 neurons is generated. 



## 5. Results 

The neural network when trained over 30 epochs has the following outputs - 

**[OUTPUTS MAY VARY SLIGHTLY BASED ON THE RANDOMNESS OF THE DATASET GENERATED]**

- The CSV file was generated successfully.
- The loss during the 1st epoch is 0.25 and this goes down to 0.15 during the 30th epoch.
- This signifies that the neural network is being trained successfully. 
- Anomalies are detected successfully.
- Rows with anomalies can be reconstructed based on their deviation and thresholds. 
- The neural network is able to identify which columns (0 indexed) the maximum anomaly/error is being detected. 
- Based on these insights we can plot various graphs. 

**E.g -** A graph of MSE against the number of rows can be plotted to identify how much significant deviation occurs in the dataset. 

![Image](https://github.com/user-attachments/assets/cb2c03f4-b467-4398-8a30-70e662be9eff)


## 6. Future Improvements

- While this dataset is being generated by us, neural networks perform better over a well defined dataset rather than a randomised dataset. 
- With a well defined dataset, we can achieve a faster learning curve.
- With a chronological dataset spanning over a year, we can analyze trends in the shipments across specific days, weeks or months.
- Considering other neural network models such as RAGs can have certain advantages.


## 7. Packages Used

- Torch 
- Pandas 
- OS 
- Matplotlib 
- Numpy



## 8. How to Run the Code

- Download the python code **(neuralnetwork.py)**
- Ensure python is installed
- Install all necessary packages
- Run `python3 neuralnetwork.py` in the terminal


## 9. Example Output 

- Let the columns be 0 indexed
- Consider row 98 : `[1, 1, 1, 0, 0, 0, 1, 1]`
- Reconstructed row 98 : `[0.62841946, 0.3495212,  0.57400507, 0.67165595, 0.8300915,  0.3375816, 0.40318963, 0.5192877,  0.45859647]`
- Errors per column : `[0.37158054, 0.65047884, 0.42599493, 0.32834405, 0.8300915,  0.3375816, 0.40318963, 0.4807123,  0.54140353]`
- Max error at column 4
